# -*- coding: utf-8 -*-
"""FPN-UNET-Generative-Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QrZo8nKKIcJzAztpCReQP7x6DErf1vQR
"""

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# pip3 install -qq torch
# pip3 install -qq torchvision
# pip3 install -qq pytorch-lightning
# pip3 install -qq monai

import torch.nn as nn
import torch
import pytorch_lightning as pl
import monai

class ConvNormDownSampling(pl.LightningModule):
    '''
    Implements Convolution + Normalisation
    '''
    def __init__(
        self, 
        in_channels,
        out_channels,
        kernel_size = 2,
        stride = 2,
        ):

        super().__init__()

        self._conv_layer = nn.Conv3d(
            in_channels = in_channels,
            out_channels = out_channels,
            kernel_size = kernel_size,
            stride = stride,
        )

        self._norm_layer = monai.networks.blocks.ADN(
            in_channels = out_channels
        )

    def forward(self, x):
        return self._norm_layer(self._conv_layer(x))

class ResidualAddAndUpsample(pl.LightningModule):
    '''
    Makes residual and 1x1 convolution block
    low_dim_tensor - expected 5D Tensor
    high_dim_tensor = expected 5D Tensor
    '''
    def __init__(self, low_dim_tensor_channel, high_dim_tensor_channel, out_channels):
        super().__init__()
        self._one_x_one_conv = nn.Conv3d(
            in_channels = high_dim_tensor_channel,
            out_channels = out_channels,
            kernel_size = 1,
            stride = 1
        )
        self._up_conv = nn.ConvTranspose3d(
            in_channels = low_dim_tensor_channel,
            out_channels = out_channels,
            kernel_size = 2,
            stride = 2,
        )
    
    def forward(self, low_dim_tensor, high_dim_tensor):
        x = self._one_x_one_conv(high_dim_tensor)
        y = self._up_conv(low_dim_tensor)

        return (x+y)

class FPN_BackBone_3D(pl.LightningModule):
    '''
    FPN backbone for the data-module

    [b_s, 1, 96, 96 96]
    '''
    def __init__(
        self, 
        in_channels=1, 
        out_channels=256,
        ):

        super().__init__()

        self._down_layer_1 = ConvNormDownSampling(in_channels = 1, out_channels = 128)
        self._down_layer_2 = ConvNormDownSampling(in_channels = 128, out_channels = 256)
        self._down_layer_3 = ConvNormDownSampling(in_channels = 256, out_channels = 512)
        self._down_layer_4 = ConvNormDownSampling(in_channels = 512, out_channels = 1024)

        self._res_layer_3 = ResidualAddAndUpsample(
            low_dim_tensor_channel = 1024,
            high_dim_tensor_channel = 512,
            out_channels = 256,
        )
        self._res_layer_2 = ResidualAddAndUpsample(
            low_dim_tensor_channel = 256,
            high_dim_tensor_channel = 256,
            out_channels = 128,

        )
        self._res_layer_1 = ResidualAddAndUpsample(
            low_dim_tensor_channel = 128,
            high_dim_tensor_channel = 128,
            out_channels = 64
        )            

    def forward(self, ip):
        d1 = self._down_layer_1 (ip)
        d2 = self._down_layer_2 (d1)
        d3 = self._down_layer_3 (d2)
        d4 = self._down_layer_4 (d3)

        u4 = self._res_layer_3 (d4, d3)
        u3 = self._res_layer_2 (u4, d2)
        u2 = self._res_layer_1 (u3, d1)

        print(u4.shape, u3.shape, u2.shape)
        return [u4, u3, u2]

# bs, channel, height, width
random_noise = torch.rand(2, 1, 96, 96, 96)

a = FPN_BackBone_3D()
a(random_noise)


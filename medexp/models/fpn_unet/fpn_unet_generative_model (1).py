# -*- coding: utf-8 -*-
"""FPN-UNET-Generative-Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QrZo8nKKIcJzAztpCReQP7x6DErf1vQR
"""

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# pip3 install -qq torch
# pip3 install -qq torchvision
# pip3 install -qq pytorch-lightning
# pip3 install -qq monai
# pip3 install -qq torchsummary

import torch.nn as nn
import torch
import pytorch_lightning as pl
import monai
from torchsummary import summary

"""### Input Tensor - [batch_size, 1, 96, 96, 96]
### Output Tensor - [batch_size, 2, 96, 96, 96]
"""

class ConvNormDownSampling(pl.LightningModule):
    '''
    Implements Convolution + Normalisation
    '''
    def __init__(
        self, 
        in_channels,
        out_channels,
        kernel_size = 2,
        stride = 2,
        ):

        super().__init__()

        self._conv_layer = nn.Conv3d(
            in_channels = in_channels,
            out_channels = out_channels,
            kernel_size = kernel_size,
            stride = stride,
        )

        self._norm_layer = monai.networks.blocks.ADN(
            in_channels = out_channels
        )

    def forward(self, x):
        return self._norm_layer(self._conv_layer(x))

class ConvNormUpSampling(pl.LightningModule):
    '''
    Implements Up-Convolution + Normalisation
    '''
    def __init__(
        self, 
        in_channels,
        out_channels,
        kernel_size = 2,
        stride = 2,
        ):

        super().__init__()

        self._conv_layer = nn.ConvTranspose3d(
            in_channels = in_channels,
            out_channels = out_channels,
            kernel_size = kernel_size,
            stride = stride,
        )

        self._norm_layer = monai.networks.blocks.ADN(
            in_channels = out_channels
        )

    def forward(self, x):
        return self._norm_layer(self._conv_layer(x))

class ResidualAddAndUpsample(pl.LightningModule):
    '''
    Makes residual and 1x1 convolution block
    low_dim_tensor - expected 5D Tensor
    high_dim_tensor = expected 5D Tensor
    '''
    def __init__(self, low_dim_tensor_channel, high_dim_tensor_channel, out_channels):
        super().__init__()
        self._one_x_one_conv = nn.Conv3d(
            in_channels = high_dim_tensor_channel,
            out_channels = out_channels,
            kernel_size = 1,
            stride = 1
        )
        self._up_conv = nn.ConvTranspose3d(
            in_channels = low_dim_tensor_channel,
            out_channels = out_channels,
            kernel_size = 2,
            stride = 2,
        )
    
    def forward(self, low_dim_tensor, high_dim_tensor):
        x = self._one_x_one_conv(high_dim_tensor)
        y = self._up_conv(low_dim_tensor)

        return (x+y)

class FPN_BackBone_3D(pl.LightningModule):
    '''
    FPN backbone for the data-module

    [b_s, 1, 96, 96 96]
    '''
    def __init__(
        self, 
        in_channels=1, 
        out_channels=256,
        ):

        super().__init__()

        self._down_layer_1 = ConvNormDownSampling(in_channels = 1, out_channels = 128)
        self._down_layer_2 = ConvNormDownSampling(in_channels = 128, out_channels = 256)
        self._down_layer_3 = ConvNormDownSampling(in_channels = 256, out_channels = 512)
        self._down_layer_4 = ConvNormDownSampling(in_channels = 512, out_channels = 1024)

        self._res_layer_3 = ResidualAddAndUpsample(
            low_dim_tensor_channel = 1024,
            high_dim_tensor_channel = 512,
            out_channels = 256,
        )
        self._res_layer_2 = ResidualAddAndUpsample(
            low_dim_tensor_channel = 256,
            high_dim_tensor_channel = 256,
            out_channels = 128,

        )
        self._res_layer_1 = ResidualAddAndUpsample(
            low_dim_tensor_channel = 128,
            high_dim_tensor_channel = 128,
            out_channels = 64
        )            

    def forward(self, ip):
        d1 = self._down_layer_1 (ip)
        d2 = self._down_layer_2 (d1)
        d3 = self._down_layer_3 (d2)
        d4 = self._down_layer_4 (d3)

        u4 = self._res_layer_3 (d4, d3)
        u3 = self._res_layer_2 (u4, d2)
        u2 = self._res_layer_1 (u3, d1)

        # print(u4.shape, u3.shape, u2.shape)
        return [u4, u3, u2]

# UNET
class UNET3DwithAttention(pl.LightningModule):
    '''
    UNet with FPN attention
    '''
    def __init__(
        self,
        in_channels,
        out_channels,
    ):
        super().__init__()
        # Layers
        self._fpn = FPN_BackBone_3D(in_channels=in_channels) # [256, 12, 12, 12][128, 24, 24, 24][64, 48, 48, 48]

        self._d_1 = ConvNormDownSampling(in_channels, 64) # 1x96x96x96 - 64x48x48x48
        self._d_2 = ConvNormDownSampling(64, 128) # 64x48x48x48 - 128x24x24x24
        self._d_3 = ConvNormDownSampling(128, 256) # 128x24x24x24 - 256x12x12x12
        self._d_4 = ConvNormDownSampling(256, 512) # 256x12x12x12 - 512x6x6x6

        self._u_4 = ConvNormUpSampling(512, 256) # 512x6x6x6 - 256x12x12x12
        self._u_3 = ConvNormUpSampling(256, 128) # 256x12x12x12 - 128x24x24x24
        self._u_2 = ConvNormUpSampling(128, 64) # 128x24x24x24 - 64x48x48x48
        self._u_1 = ConvNormUpSampling(64, out_channels) # 64x48x48x48 - 2x96x96x96

    def forward(self, x, noise):
        '''
        noise - random noise to generate attention maps
        x - input image

        noise is same dimensional as x
        '''
        # attention maps from FPN Backbone
        attn_mp = [torch.sigmoid(t) for t in self._fpn(noise)]

        # Downsample 
        o_d_1 = self._d_1(x)
        o_d_2 = self._d_2(o_d_1)
        o_d_3 = self._d_3(o_d_2)
        o_d_4 = self._d_4(o_d_3)

        x_low = o_d_4 # For understanding

        # Upsample and attention (dot product attention)
        o_u_4 = (self._u_4(x_low) + o_d_3) * attn_mp[0]
        o_u_3 = (self._u_3(o_u_4) + o_d_2) * attn_mp[1]
        o_u_2 = (self._u_2(o_u_3) + o_d_1) * attn_mp[2]
        o_u_1 = self._u_1(o_u_2)

        return o_u_1

# bs, channel, height, width
random_noise = torch.rand(2, 1, 96, 96, 96)

a = FPN_BackBone_3D()
a(random_noise);

b = ConvNormDownSampling(1, 2)
print(b(random_noise).size())

c = ConvNormUpSampling(1, 2)
print(c(random_noise).size())

net = UNET3DwithAttention(1, 2)
x = torch.rand(8, 1, 96, 96, 96)
noise = torch.rand(8, 1, 96, 96, 96)

